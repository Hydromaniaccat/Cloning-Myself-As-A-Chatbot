{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run finetuning with my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "import os\n",
    "import requests\n",
    "\n",
    "sess = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model_name = \"124M\"\n",
    "model_name = \"355M\"\n",
    "#model_name = \"774M\"\n",
    "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
    "    print(f\"Downloading {model_name} model...\")\n",
    "    gpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/124M/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model for me\n",
    "name = 'george'\n",
    "file_name = \"discord_logs_just_my_tokens.txt\"\n",
    "\n",
    "gpt2.finetune(sess,\n",
    "              file_name,\n",
    "              model_name=model_name,\n",
    "              steps=1000,\n",
    "              run_name=name,\n",
    "              save_every=250,\n",
    "              overwrite=True)   # steps is max number of training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model for alen\n",
    "name = 'alen'\n",
    "file_name = \"discord_logs_just_alen_tokens.txt\"\n",
    "\n",
    "gpt2.finetune(sess,\n",
    "              file_name,\n",
    "              model_name=model_name,\n",
    "              steps=1000,\n",
    "              run_name=name,\n",
    "              save_every=250,\n",
    "              overwrite=True)   # steps is max number of training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.load_gpt2(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=20\n",
    "p=.9\n",
    "t=.5\n",
    "max_history=4\n",
    "\n",
    "history = []\n",
    "start_text = \"What do you think of President Trump?\"\n",
    "\n",
    "bots = ['george', 'alen']\n",
    "start_tokens = ['<|BrainSquid#1538:|>', '<|alen#8819:|>']\n",
    "\n",
    "print('Topic = ' + start_text)\n",
    "history.append(start_text)\n",
    "counter = 0\n",
    "error_count = 0\n",
    "while True:\n",
    "    \n",
    "    if counter == 0:\n",
    "        out_ids = gpt2.generate(sess, run_name=bots[counter], prefix=' '.join(history) + \" \" + start_tokens[counter], truncate=\"<|endoftext|>\", temperature=t, top_k=k, top_p=p, include_prefix=False, return_as_list=True)\n",
    "    else:\n",
    "        out_ids = gpt2.generate(sess, run_name=bots[counter], prefix=' '.join(history) + \" \" + start_tokens[counter], truncate=\"<|endoftext|>\", temperature=t, top_k=k, top_p=p, include_prefix=False, return_as_list=True)\n",
    "    #Append output to history\n",
    "    output = ' '.join(out_ids)\n",
    "    \n",
    "    for start_token in start_tokens:\n",
    "        output = output.split(start_token)[0]\n",
    "    \n",
    "    if sum([x in output for x in history]) == len(history):\n",
    "        #retry\n",
    "        error_count += 1\n",
    "        print('ERROR ' + str(error_count), end='\\r')\n",
    "        continue\n",
    "        \n",
    "    history.append(output)\n",
    "    history = history[-(2*max_history+1):]\n",
    "    print(\"BOT \" + str(bots[counter]) + ' : ' + output)\n",
    "    counter = (counter + 1) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "p=.9\n",
    "t=.5\n",
    "max_history=4\n",
    "\n",
    "start_token = '<|BrainSquid#1538:|>'\n",
    "start_token2 = '<|alen#8819:|>'\n",
    "history = []\n",
    "start_text = \"What do you think of President Trump?\"\n",
    "print('Topic = ' + start_text)\n",
    "history.append(start_text)\n",
    "counter = 0\n",
    "while True:\n",
    "    \n",
    "    if counter:\n",
    "        out_ids = gpt2.generate(sess, run_name='george', prefix=' '.join(history) + \" \" + start_token, truncate=\"<|endoftext|>\", temperature=t, top_k=k, top_p=p, include_prefix=False, return_as_list=True)\n",
    "    else:\n",
    "        out_ids = gpt2.generate(sess, run_name='alen', prefix=' '.join(history) + \" \" + start_token2, truncate=\"<|endoftext|>\", temperature=t, top_k=k, top_p=p, include_prefix=False, return_as_list=True)\n",
    "    #Append output to history\n",
    "    output = ' '.join(out_ids)\n",
    "    output = output.split(start_token)[0]\n",
    "    output = output.split(start_token2)[0]\n",
    "    \n",
    "    if sum([x in output for x in history]) == len(history):\n",
    "        #retry\n",
    "        print('ERROR')\n",
    "        continue\n",
    "        \n",
    "    history.append(output)\n",
    "    history = history[-(2*max_history+1):]\n",
    "    print(\"Bot \" + str(counter) + ' : ' + output)\n",
    "    counter = (counter + 1) % 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 tensorflow==1.5",
   "language": "python",
   "name": "tf15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
